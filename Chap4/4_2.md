**使用最小训练误差作为决策树划分选择准则的缺陷。**
*Answer* The decision tree constructed via the "minimum training loss"
threshold tends to have the overfitting problem. That is, it can't generalize
to the testset, which is the goal of any machine learning algorithm.

4.1 is an extreme case, where we've proved you can *always* get a 0 training
error for datasets with some specific property; in this case, the decision tree
has learnt everything about the training set, which is guranteed to be
overfitting.
